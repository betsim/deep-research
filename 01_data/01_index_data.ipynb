{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/1TB Home SSD/GitHub/_ STAT/_ machinelearningZH/deep-research/.venv/lib/python3.11/site-packages/spacy/cli/_util.py:23: DeprecationWarning: Importing 'parser.split_arg_string' is deprecated, it will only be available in 'shell_completion' in Click 9.0.\n",
      "  from click.parser import split_arg_string\n",
      "/Volumes/1TB Home SSD/GitHub/_ STAT/_ machinelearningZH/deep-research/.venv/lib/python3.11/site-packages/weasel/util/config.py:8: DeprecationWarning: Importing 'parser.split_arg_string' is deprecated, it will only be available in 'shell_completion' in Click 9.0.\n",
      "  from click.parser import split_arg_string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 10 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import weaviate\n",
    "from weaviate.classes.config import Property, DataType\n",
    "import weaviate.classes as wvc\n",
    "import weaviate.classes.config as wc\n",
    "import atexit\n",
    "from utils import load_config\n",
    "from utils import chunk_text\n",
    "import tiktoken\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 333 entries, 0 to 332\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   identifier   333 non-null    object        \n",
      " 1   date         333 non-null    datetime64[ns]\n",
      " 2   title        333 non-null    object        \n",
      " 3   link         333 non-null    object        \n",
      " 4   text         333 non-null    object        \n",
      " 5   token_count  333 non-null    int64         \n",
      "dtypes: datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 5.4 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"_data/01_KRP_1994.parq\")\n",
    "df[\"token_count\"] = df[\"text\"].apply(lambda x: len(enc.encode(x)))\n",
    "# For simplicity, we will filter out very long documents.\n",
    "df = df[df[\"token_count\"] <= 5_000]\n",
    "cols = [\"identifier\", \"date\", \"title\", \"ref\", \"text\", \"token_count\"]\n",
    "df = df[cols]\n",
    "df.rename(columns={\"ref\": \"link\"}, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.info(memory_usage=\"deep\")\n",
    "df.to_parquet(\"_data/02_KRP_selec.parq\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"_data/02_KRP_selec.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d2d201e2d848d9895c38f4d3f6464d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=34), Label(value='0 / 34'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1671 entries, 0 to 1670\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   identifier   1671 non-null   object        \n",
      " 1   date         1671 non-null   datetime64[ns]\n",
      " 2   title        1671 non-null   object        \n",
      " 3   link         1671 non-null   object        \n",
      " 4   token_count  1671 non-null   int64         \n",
      " 5   chunk_text   1671 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 4.7 MB\n"
     ]
    }
   ],
   "source": [
    "# We shuffle the dataframe to make sure that parallel processing is more efficient.\n",
    "results = df.sample(frac=1).parallel_apply(\n",
    "    chunk_text, max_token_count=500, overlap_tokens=100, axis=1\n",
    ")\n",
    "df_chunks = pd.DataFrame(\n",
    "    [y for x in results.tolist() for y in x], columns=[\"identifier\", \"chunk_text\"]\n",
    ")\n",
    "\n",
    "df_chunks = pd.merge(\n",
    "    df.drop(columns=[\"text\"]), df_chunks, left_on=\"identifier\", right_on=\"identifier\"\n",
    ")\n",
    "\n",
    "df_chunks.info(memory_usage=\"deep\")\n",
    "df_chunks.to_parquet(\"_data/03_KRP_chunks.parq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"_data/03_KRP_chunks.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 512\n"
     ]
    }
   ],
   "source": [
    "model_path = \"intfloat/multilingual-e5-small\"\n",
    "model = SentenceTransformer(\n",
    "    model_path,\n",
    "    trust_remote_code=True,\n",
    "    device=\"mps\",  # Use \"cuda\" for CUDA GPUs, \"mps\" for Mac, \"cpu\" for CPU\n",
    ")\n",
    "print(\"Max Sequence Length:\", model.max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290e11f055e8449b9382b9e85273442e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = model.encode(\n",
    "    df.chunk_text.values,\n",
    "    batch_size=16,\n",
    "    convert_to_tensor=False,\n",
    "    normalize_embeddings=True,\n",
    "    show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embeddings\"] = list(embeddings)\n",
    "df.to_parquet(\"_data/04_KRP_embed.parq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "\n",
    "def initialize_weaviate(collection_name: str = None):\n",
    "    \"\"\"Initialize Weaviate client and collection\"\"\"\n",
    "    if collection_name is None:\n",
    "        collection_name = config[\"weaviate\"][\"collection_name\"]\n",
    "\n",
    "    try:\n",
    "        client = weaviate.connect_to_local(\n",
    "            port=config[\"weaviate\"][\"port\"], grpc_port=config[\"weaviate\"][\"grpc_port\"]\n",
    "        )\n",
    "    except:\n",
    "        raise\n",
    "    collection = client.collections.get(collection_name)\n",
    "\n",
    "    # Register cleanup function\n",
    "    def cleanup_weaviate():\n",
    "        try:\n",
    "            client.close()\n",
    "        except Exception as e:\n",
    "            raise\n",
    "\n",
    "    atexit.register(cleanup_weaviate)\n",
    "\n",
    "    return client, collection\n",
    "\n",
    "\n",
    "client, collection = initialize_weaviate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"_data/04_KRP_embed.parq\")\n",
    "df.date = pd.to_datetime(df.date, format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grpcMaxMessageSize': 104858000,\n",
       " 'hostname': 'http://[::]:8080',\n",
       " 'modules': {},\n",
       " 'version': '1.31.5'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Get the meta endpoint description of weaviate.\n",
    "display(client.get_meta())\n",
    "\n",
    "# Ping Weaviate’s live and ready state.\n",
    "print(client.is_live())\n",
    "print(client.is_ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.sync.Collection at 0x175c1b5d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the collection already exists, delete it.\n",
    "try:\n",
    "    client.collections.delete(config[\"weaviate\"][\"collection_name\"])\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f\"Collection '{config['weaviate']['collection_name']}' does not exist.\")\n",
    "\n",
    "# Create the collection with the specified properties.\n",
    "client.collections.create(\n",
    "    config[\"weaviate\"][\"collection_name\"],\n",
    "    vectorizer_config=wc.Configure.Vectorizer.none(),\n",
    "    inverted_index_config=wvc.config.Configure.inverted_index(\n",
    "        bm25_b=0.75,\n",
    "        bm25_k1=1.2,\n",
    "        # stopwords_additions=None,\n",
    "        # stopwords_preset=None,\n",
    "        # stopwords_removals=None,\n",
    "    ),\n",
    "    properties=[\n",
    "        Property(name=\"identifier\", data_type=DataType.TEXT),\n",
    "        Property(name=\"title\", data_type=DataType.TEXT),\n",
    "        Property(name=\"text\", data_type=DataType.TEXT),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KRP_STAZH\n"
     ]
    }
   ],
   "source": [
    "# List all collections.\n",
    "for v in client.collections.list_all().values():\n",
    "    print(v.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://weaviate.io/developers/weaviate/client-libraries/python#batch-sizing\n",
    "with collection.batch.fixed_size(batch_size=200, concurrent_requests=8) as batch:\n",
    "    for idx, data in enumerate(df.to_dict(orient=\"records\")):\n",
    "        properties = {\n",
    "            \"identifier\": data[\"identifier\"],\n",
    "            \"title\": data[\"title\"],\n",
    "            \"text\": data[\"chunk_text\"],\n",
    "        }\n",
    "        batch.add_object(properties=properties, vector=data[\"embeddings\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1671\n"
     ]
    }
   ],
   "source": [
    "# Get total count of all items in the collection.\n",
    "response = collection.aggregate.over_all(total_count=True)\n",
    "print(response.total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Lexical Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einzelinitiative Odile Wild, Zürich, vom 9. Juni 1994 betreffend Gleichstellung von Mann und Frau im Steuergesetz KR-Nr. 193/1994\n",
      "Mitteilungen\n",
      "Mitteilungen\n",
      "Einzelinitiative Dr. Bernhard Wehrli, Feldbach, betreffend Änderung des PBG Bericht und Antrag des Regierungsrates vom 19. August 1992 und gleichlautender Antrag der Kommission vom 2. Dezember 1993 3249\n"
     ]
    }
   ],
   "source": [
    "query = \"Was ist zu Steuerreformen entschieden worden?\"\n",
    "\n",
    "response = collection.query.bm25(\n",
    "    query=query,\n",
    "    # query_properties=[\"title\"], # Define which fields to search over.\n",
    "    offset=0,\n",
    "    limit=10,\n",
    "    auto_limit=2,\n",
    "    return_metadata=wvc.query.MetadataQuery(score=True, distance=True, certainty=True),\n",
    "    # filters=wvc.query.Filter.by_property(\"year\").equal(2012),\n",
    "    #  filters=wvc.query.Filter.by_property(\"year\").less_than(2012),\n",
    "    #  auto_limit=True,\n",
    ")\n",
    "\n",
    "seen = []\n",
    "final_results = []\n",
    "\n",
    "for item in response.objects:\n",
    "    if item.properties[\"identifier\"] in seen:\n",
    "        continue\n",
    "    final_results.append(item.properties[\"title\"])\n",
    "    seen.append(item.properties[\"identifier\"])\n",
    "for elem in final_results:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Hybrid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"intfloat/multilingual-e5-small\"\n",
    "model = SentenceTransformer(\n",
    "    model_path,\n",
    "    trust_remote_code=True,\n",
    "    device=\"mps\",  # Use \"cuda\" for GPU, \"mps\" for Mac, \"cpu\" for CPU\n",
    ")\n",
    "\n",
    "def embed_query(query):\n",
    "    return model.encode(query, convert_to_tensor=False, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einzelinitiative Odile Wild, Zürich, vom 9. Juni 1994 betreffend Gleichstellung von Mann und Frau im Steuergesetz KR-Nr. 193/1994\n",
      "Verordnung über die Quellensteuer für ausländische Arbeitnehmer Quellensteuerverordnung Antrag des Regierungsrates vom 2. Februar 1994 und gleichlautender Antrag der Kommission vom 5. Mai 1994 3374 Verordnung über die Quellensteuer für natürliche und juristische Personen ohne steuerrechtlichen Wohnsitz oder Aufenthalt in der Schweiz Quellensteuerverordnung Antrag des Regierungsrates vom 2. Februar 1994 und gleichlautender Antrag der Kommission vom 5. Mai 1994 3375\n",
      "Einzelinitiative Beat Müller, Zürich, vom 5. Juli 1993 betreffend Änderung des Steuergesetzes KR-Nr. 227/1993\n"
     ]
    }
   ],
   "source": [
    "query_embedding = embed_query(query)\n",
    "\n",
    "response = collection.query.hybrid(\n",
    "    query=query,\n",
    "    vector=list(query_embedding),\n",
    "    limit=10,\n",
    "    auto_limit=2,\n",
    "    alpha=0.7,\n",
    "    fusion_type=wvc.query.HybridFusion.RELATIVE_SCORE,\n",
    ")\n",
    "\n",
    "seen = []\n",
    "final_results = []\n",
    "\n",
    "for item in response.objects:\n",
    "    if item.properties[\"identifier\"] in seen:\n",
    "        continue\n",
    "    final_results.append(item.properties[\"title\"])\n",
    "    seen.append(item.properties[\"identifier\"])\n",
    "\n",
    "for elem in final_results:\n",
    "    print(elem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
